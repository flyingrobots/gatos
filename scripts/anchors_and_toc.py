#!/usr/bin/env python3
"""
Add explicit HTML anchors for headings (H1..H5) and insert/update a GitHub-style
Table of Contents in Markdown files.

Anchors:
- For any heading (levels 1..5), insert an <a id="..."></a> line immediately after
  the heading, unless present.
- If the heading begins with a numeric section like "5." or "5.3", add numeric
  anchors: "5", "5.3" and a collapsed "53" convenience id.
- Also add a GitHub-style slug anchor (lowercased, spaces -> dashes, punctuation removed)
  to provide a stable id even without numbers.

TOC:
- Insert or update a block between markers:
  <!-- AUTOGENERATED TOC START --> ... <!-- AUTOGENERATED TOC END -->
- If markers are absent, the TOC is inserted after the first H1.
- Includes H2..H5 by default (skips the document title H1 to reduce noise).

Usage:
  python scripts/anchors_and_toc.py --write           # apply across docs/**/*.md
  python scripts/anchors_and_toc.py --check           # non-zero if changes needed
  python scripts/anchors_and_toc.py --paths docs/SPEC.md docs/TECH-SPEC.md
"""
import argparse
import html
import pathlib
import re
import sys

ROOT = pathlib.Path(__file__).resolve().parents[1]

MD_GLOB = [ROOT / "docs"]

HEADING_RE = re.compile(r"^(?P<hashes>#{1,5})\s+(?P<text>.+?)\s*$")
NUM_PREFIX_RE = re.compile(r"^(?P<num>\d+(?:\.\d+)*)\b")

TOC_START = "<!-- AUTOGENERATED TOC START -->"
TOC_END = "<!-- AUTOGENERATED TOC END -->"

def slugify_kebab(text: str) -> str:
    """Canonical single-dash kebab-case id.
    - lowercase
    - strip markdown links/backticks
    - keep letters/digits and dots (for versions like v0.3)
    - convert spaces/underscores to hyphens; collapse multiple hyphens
    """
    t = text.strip().lower()
    t = re.sub(r"`+", "", t)
    t = re.sub(r"\[([^\]]+)\]\([^)]*\)", r"\1", t)
    # replace underscores with spaces to normalize
    t = t.replace("_", " ")
    # remove everything except alnum, dot, space, hyphen
    t = re.sub(r"[^a-z0-9\-\s\.]+", "", t)
    t = re.sub(r"\s+", "-", t)
    t = re.sub(r"-+", "-", t).strip("-")
    return t

def make_anchor_line(text: str) -> str:
    # Single canonical id only (no numeric variants): strict kebab-case
    slug = slugify_kebab(text)
    if not slug:
        return ""
    return f"<a id=\"{html.escape(slug)}\"></a>\n"

ANCHOR_RE = re.compile(r"<a\s+id=\"([^\"]+)\"\s*></a>")

def extract_anchor_ids(line: str) -> list[str]:
    return ANCHOR_RE.findall(line)

def is_anchor_line(line: str) -> bool:
    return bool(ANCHOR_RE.search(line))

def build_toc(headings: list[tuple[int,str,str]]) -> str:
    lines = [TOC_START, "\n"]
    for level, text, hid in headings:
        # indent 2 spaces per level offset from H2 (i.e., level 2 -> 0 indent)
        indent = max(0, level - 2) * 2
        lines.append(" " * indent + f"- [{text}](#{hid})\n")
    lines.append("\n" + TOC_END + "\n")
    return "".join(lines)

def process_file(path: pathlib.Path) -> tuple[bool, str]:
    text = path.read_text(encoding="utf-8")
    lines = text.splitlines(keepends=True)
    changed = False
    out = []
    in_code = False
    headings_for_toc: list[tuple[int,str,str]] = []
    used_ids: set[str] = set()
    i = 0
    def is_blank(s: str) -> bool:
        return s.strip() == ""

    while i < len(lines):
        line = lines[i]
        # code fence toggle
        if line.strip().startswith("```"):
            in_code = not in_code
            out.append(line)
            i += 1
            continue
        if not in_code:
            m = HEADING_RE.match(line)
            if m:
                level = len(m.group("hashes"))
                text_content = m.group("text").strip()
                # Ensure a blank line BEFORE heading (unless at file start)
                if out and not is_blank(out[-1]):
                    out.append("\n")
                out.append(line)
                # (TOC entries are appended after id is assigned)
                # Look ahead a few lines to collapse duplicate anchors and/or insert if missing.
                j = i + 1
                # Collect consecutive blank or anchor lines immediately after the heading
                collected: list[str] = []
                while j < len(lines):
                    nxt = lines[j]
                    if nxt.strip() == "":
                        collected.append(nxt)
                        j += 1
                        continue
                    if is_anchor_line(nxt):
                        collected.append(nxt)
                        j += 1
                        continue
                    break
                # Always compute canonical single id (ensure file-unique by suffixing -2, -3, â€¦)
                base = slugify_kebab(text_content)
                hid = base
                suffix = 2
                while hid in used_ids:
                    hid = f"{base}-{suffix}"
                    suffix += 1
                used_ids.add(hid)
                canonical = f"<a id=\"{html.escape(hid)}\"></a>\n"
                # Ensure a blank line AFTER heading before anchors/content
                if not collected or (collected and not is_blank(collected[0])):
                    out.append("\n")
                if collected:
                    if canonical:
                        out.append(canonical)
                    # if the collected block differs from canonical single line, mark changed
                    if not (len(collected) == 1 and collected[0] == canonical):
                        changed = True
                else:
                    if canonical:
                        out.append(canonical)
                        changed = True
                # collect for TOC (skip H1)
                if level >= 2:
                    headings_for_toc.append((level, text_content, hid))
                # Skip over the collected lines in the input
                i = j
                continue
        out.append(line)
        i += 1

    new_text = "".join(out)

    # Insert/replace TOC
    if headings_for_toc:
        toc = build_toc(headings_for_toc)
        if TOC_START in new_text and TOC_END in new_text:
            new_text2 = re.sub(
                re.escape(TOC_START) + r"[\s\S]*?" + re.escape(TOC_END),
                toc.strip(),
                new_text,
                flags=re.MULTILINE,
            )
            if new_text2 != new_text:
                changed = True
                new_text = new_text2
        else:
            # Insert after first H1
            m = re.search(r"^#\s+.+$", new_text, flags=re.M)
            if m:
                insert_pos = m.end()
                new_text = new_text[:insert_pos] + "\n\n" + toc + new_text[insert_pos:]
                changed = True

    return changed, new_text

def iter_markdown(paths: list[pathlib.Path]):
    for p in paths:
        if p.is_file() and p.suffix == ".md":
            yield p
        elif p.is_dir():
            yield from p.rglob("*.md")

def main() -> int:
    ap = argparse.ArgumentParser()
    ap.add_argument("--write", action="store_true")
    ap.add_argument("--check", action="store_true")
    ap.add_argument("--paths", nargs="*", default=[str(p) for p in MD_GLOB])
    args = ap.parse_args()

    targets = [pathlib.Path(p) for p in args.paths]
    changed_any = False
    for md in iter_markdown(targets):
        chg, out = process_file(md)
        if chg:
            changed_any = True
            if args.write:
                md.write_text(out, encoding="utf-8")
            print(f"would change: {md}")

    if args.check and changed_any:
        return 2
    return 0

if __name__ == "__main__":
    sys.exit(main())
