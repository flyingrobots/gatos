#!/usr/bin/env node
// Normalize Markdown files via unified/remark:
// - parse → apply plugins → stringify
// - insert TOC between <!-- AUTOGENERATED TOC START/END --> markers
// - add stable anchors (slug + optional numeric) exactly once per heading
// - linkify SPEC/TECH-SPEC § references
// - fix nested relative links to absolute site paths

import { unified } from 'unified'
import remarkParse from 'remark-parse'
import remarkStringify from 'remark-stringify'
import remarkGfm from 'remark-gfm'
import remarkFrontmatter from 'remark-frontmatter'
import remarkSlug from 'remark-slug'
import { visit } from 'unist-util-visit'
import { toString } from 'mdast-util-to-string'
import { globby } from 'globby'
import fs from 'node:fs/promises'
import path from 'node:path'
import Slugger from 'github-slugger'

const ROOT = path.resolve(process.cwd())
const DOCS = path.join(ROOT, 'docs')

const START = '<!-- AUTOGENERATED TOC START -->'
const END = '<!-- AUTOGENERATED TOC END -->'

function anchorsMulti() {
  return (tree, file) => {
    const slugger = new Slugger()
    visit(tree, 'heading', (node, idx, parent) => {
      // Skip if parent missing
      if (!parent) return
      const text = toString(node).trim()
      // Compute slug id as GitHub-like; use a single canonical id (no numeric variants)
      const slugId = slugger.slug(text)
      // Remove any existing adjacent HTML anchors following the heading
      let j = idx + 1
      let collected = []
      while (j < parent.children.length) {
        const nxt = parent.children[j]
        if (nxt.type === 'html' && /<a\s+id=/.test(nxt.value || '')) {
          collected.push(j)
          j++
          continue
        }
        if (nxt.type === 'thematicBreak' || nxt.type === 'paragraph' || nxt.type === 'heading' || nxt.type === 'list') break
        if (nxt.type === 'text' && nxt.value.trim() === '') { j++; continue }
        break
      }
      // Drop duplicates
      if (collected.length > 0) {
        for (let k = collected.length - 1; k >= 0; k--) parent.children.splice(collected[k], 1)
      }
      // Insert a single normalized anchor html node after the heading
      const html = `<a id="${slugId}"></a>\n`
      parent.children.splice((idx ?? 0) + 1, 0, { type: 'html', value: html })
    })
  }
}

function tocMarkers() {
  return (tree, file) => {
    // Find markers as html nodes and replace content in between with generated list of headings (H2..H4)
    const nodes = tree.children
    let start = -1, end = -1
    for (let i = 0; i < nodes.length; i++) {
      const n = nodes[i]
      if (n.type === 'html' && typeof n.value === 'string') {
        if (n.value.includes(START)) start = i
        if (n.value.includes(END)) { end = i; break }
      }
    }
    if (start >= 0 && end > start) {
      // collect headings
      const items = []
      visit(tree, 'heading', (h) => {
        if (h.depth >= 2 && h.depth <= 4) {
          const text = toString(h).trim()
          // Always use the slug anchor for stability; numeric anchors are not emitted
          const slug = (h.data && h.data.hProperties && h.data.hProperties.id) || new Slugger().slug(text)
          const anchor = slug
          items.push({ depth: h.depth, text, anchor })
        }
      })
      // Build a very simple HTML TOC to preserve our marker block
      // We keep it as a markdown list for readability
      const lines = [START, '\n']
      for (const it of items) {
        const indent = '  '.repeat(Math.max(0, it.depth - 2))
        lines.push(`${indent}- [${it.text}](#${it.anchor})\n`)
      }
      // Close immediately without extra spacer line before END for compactness
      lines.push(END)
      const htmlNode = { type: 'html', value: lines.join('') }
      // Replace everything between markers with a single node
      nodes.splice(start, end - start + 1, htmlNode)
    }
  }
}

function linkifySpec() {
  const SPEC = /\bSPEC\s*§\s*(\d+(?:\.(?:\d+|x))?)\b/g
  const TECH = /\bTECH-SPEC\s*§\s*(\d+(?:\.(?:\d+|x))?)\b/g
  return (tree) => {
    visit(tree, (node, index, parent) => {
      if (node.type !== 'text' || !parent || parent.type === 'link' || parent.type === 'inlineCode' || parent.type === 'code') return
      let value = node.value
      if (!value) return
      const replace = (re, base) => {
        value = value.replace(re, (_, s) => `[${base} §${s}](/${base.replace(/-/g, '')}#${s})`)
      }
      const before = value
      replace(SPEC, 'SPEC')
      replace(TECH, 'TECH-SPEC')
      if (value !== before) parent.children[index] = { type: 'text', value }
    })
  }
}

function pathFixer() {
  return (tree, file) => {
    // Convert ./SPEC.md -> /SPEC style; only in link nodes
    visit(tree, 'link', (n) => {
      if (typeof n.url !== 'string') return
      n.url = n.url
        .replace(/^\.\/SPEC\.md(#.*)?$/, '/SPEC$1' )
        .replace(/^\.\/TECH-SPEC\.md(#.*)?$/, '/TECH-SPEC$1' )
    })
  }
}

async function processOne(absPath, write) {
  const orig = await fs.readFile(absPath, 'utf8')
  const file = await unified()
    .use(remarkParse)
    .use(remarkFrontmatter, ['yaml'])
    .use(remarkGfm)
    .use(remarkSlug)
    .use(anchorsMulti)
    .use(tocMarkers)
    .use(linkifySpec)
    .use(pathFixer)
    .use(remarkStringify, {
      bullet: '-',
      fences: true,
      listItemIndent: 'one',
      rule: '-',
      tightDefinitions: true,
      // keep our inline HTML anchor blocks
      allowDangerousHtml: true
    })
    .process(orig)

  const out = String(file)
  if (write && out !== orig) await fs.writeFile(absPath, out, 'utf8')
  return out === orig
}

async function main() {
  const write = process.argv.includes('--write')
  const check = process.argv.includes('--check')
  const patterns = process.argv.filter((a) => !a.startsWith('--')).slice(2)
  const globs = patterns.length ? patterns : [path.join('docs', '**/*.md')]
  const files = await globby(globs, { gitignore: true })
  let ok = true
  for (const rel of files) {
    const abs = path.resolve(rel)
    const same = await processOne(abs, write)
    if (!same) ok = false
  }
  if (check && !ok) {
    console.error('[normalize] differences found; run docs:normalize to update')
    process.exit(2)
  }
}

main().catch((e) => { console.error(e); process.exit(1) })
